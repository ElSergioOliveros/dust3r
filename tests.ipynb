{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876e95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soliverosb/3dStuff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/soliverosb/dust3r/dust3r/cloud_opt/base_opt.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "from dust3r.inference import inference\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images_from_PIL\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "\n",
    "import os\n",
    "import PIL.Image \n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a491974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177fb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoseAnnotations(file_path, scene_name, num_annots):\n",
    "    with open(file_path, 'r') as file:\n",
    "        original_annots = json.load(file)\n",
    "    \n",
    "    scene_annots = [annot for annot in original_annots if annot['sequence_name'] == scene_name]\n",
    "\n",
    "    scene_annots.sort(key=lambda x: x['frame_number'])\n",
    "    \n",
    "    annots = np.zeros((num_annots, 4, 4))\n",
    "    \n",
    "    for i in range(num_annots):\n",
    "        annot_info = scene_annots[i]\n",
    "\n",
    "        R = annot_info['viewpoint']['R']\n",
    "        T = annot_info['viewpoint']['T']\n",
    "        annots[i, :3, :3] = R\n",
    "        annots[i, :3, 3] = T\n",
    "        annots[i, 3, 3] = 1\n",
    "    \n",
    "    return annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68f713",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 44.45 GiB of which 9.69 MiB is free. Process 2735677 has 43.43 GiB memory in use. Including non-PyTorch memory, this process has 1018.00 MiB memory in use. Of the allocated memory 756.81 MiB is allocated by PyTorch, and 1.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m niter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[1;32m      6\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnaver/DUSt3R_ViTLarge_BaseDecoder_512_dpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAsymmetricCroCo3DStereo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m imageDf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/soliverosb/dataFor3D/carScene.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n",
      "File \u001b[0;32m~/3dStuff/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/3dStuff/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/3dStuff/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 915 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/3dStuff/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/3dStuff/lib/python3.10/site-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/3dStuff/lib/python3.10/site-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 44.45 GiB of which 9.69 MiB is free. Process 2735677 has 43.43 GiB memory in use. Including non-PyTorch memory, this process has 1018.00 MiB memory in use. Of the allocated memory 756.81 MiB is allocated by PyTorch, and 1.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "schedule = 'cosine'\n",
    "lr = 0.01\n",
    "niter = 300\n",
    "\n",
    "model_name = \"naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt\"\n",
    "\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e2bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93876_187487/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93876_187487/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93876_187487/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93876_187487/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93876_187487/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93876_187487/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93876_187487/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93876_187487/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93906_187608/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93906_187608/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93906_187608/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93906_187608/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93906_187608/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93906_187608/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93906_187608/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_93906_187608/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_94093_188424/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_94093_188424/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_94093_188424/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_94093_188424/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_94093_188424/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_94093_188424/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_94093_188424/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/604_94093_188424/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95644_191861/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95644_191861/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95644_191861/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95644_191861/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95644_191861/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95644_191861/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95644_191861/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95644_191861/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95658_192033/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95658_192033/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95658_192033/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95658_192033/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95658_192033/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95658_192033/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95658_192033/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/apple/608_95658_192033/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/71_6304_14247/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/71_6304_14247/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/71_6304_14247/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/71_6304_14247/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/71_6304_14247/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/71_6304_14247/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/71_6304_14247/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/71_6304_14247/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/168_18361_34847/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/168_18361_34847/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/168_18361_34847/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/168_18361_34847/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/168_18361_34847/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/168_18361_34847/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/168_18361_34847/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/168_18361_34847/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/186_20091_37188/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/186_20091_37188/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/186_20091_37188/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/186_20091_37188/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/186_20091_37188/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/186_20091_37188/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/186_20091_37188/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/186_20091_37188/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/195_21031_44256/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/195_21031_44256/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/195_21031_44256/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/195_21031_44256/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/195_21031_44256/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/195_21031_44256/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/195_21031_44256/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/195_21031_44256/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/339_35045_62920/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/339_35045_62920/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/339_35045_62920/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/339_35045_62920/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/339_35045_62920/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/339_35045_62920/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/339_35045_62920/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/baseballbat/339_35045_62920/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/540_79069_153186/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/540_79069_153186/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/540_79069_153186/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/540_79069_153186/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/540_79069_153186/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/540_79069_153186/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/540_79069_153186/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/540_79069_153186/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_79694_154743/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_79694_154743/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_79694_154743/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_79694_154743/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_79694_154743/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_79694_154743/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_79694_154743/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_79694_154743/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_80040_155950/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_80040_155950/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_80040_155950/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_80040_155950/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_80040_155950/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_80040_155950/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_80040_155950/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/555_80040_155950/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/566_81772_162221/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/566_81772_162221/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/566_81772_162221/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/566_81772_162221/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/566_81772_162221/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/566_81772_162221/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/566_81772_162221/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/566_81772_162221/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/575_84695_167609/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/575_84695_167609/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/575_84695_167609/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/575_84695_167609/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/575_84695_167609/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/575_84695_167609/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/575_84695_167609/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/bicycle/575_84695_167609/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/48_2742_8095/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/48_2742_8095/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/48_2742_8095/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/48_2742_8095/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/48_2742_8095/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/48_2742_8095/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/48_2742_8095/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/48_2742_8095/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/396_49386_97450/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/396_49386_97450/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/396_49386_97450/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/396_49386_97450/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/396_49386_97450/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/396_49386_97450/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/396_49386_97450/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/396_49386_97450/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/397_50319_98835/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/397_50319_98835/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/397_50319_98835/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/397_50319_98835/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/397_50319_98835/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/397_50319_98835/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/397_50319_98835/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/397_50319_98835/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/398_50447_98995/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/398_50447_98995/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/398_50447_98995/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/398_50447_98995/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/398_50447_98995/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/398_50447_98995/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/398_50447_98995/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/398_50447_98995/images/frame000008.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/401_52103_102180/images/frame000001.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/401_52103_102180/images/frame000002.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/401_52103_102180/images/frame000003.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/401_52103_102180/images/frame000004.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/401_52103_102180/images/frame000005.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/401_52103_102180/images/frame000006.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/401_52103_102180/images/frame000007.jpg\n",
      "/home/soliverosb/OWL/src/external_repositories/data/tv/401_52103_102180/images/frame000008.jpg\n"
     ]
    }
   ],
   "source": [
    "root = '/home/soliverosb/OWL/src/external_repositories/data'\n",
    "\n",
    "object_paths = {\n",
    "    'apple': ['604_93876_187487', '604_93906_187608', '604_94093_188424', '608_95644_191861', '608_95658_192033'],\n",
    "    'baseballbat': ['71_6304_14247', '168_18361_34847', '186_20091_37188', '195_21031_44256', '339_35045_62920'],\n",
    "    'bicycle': ['540_79069_153186', '555_79694_154743', '555_80040_155950', '566_81772_162221', '575_84695_167609'],\n",
    "    'tv': ['48_2742_8095', '396_49386_97450', '397_50319_98835', '398_50447_98995', '401_52103_102180']\n",
    "}\n",
    "\n",
    "n = 8\n",
    "\n",
    "for object_name, scene_names in object_paths.items():\n",
    "    for scene in scene_names:\n",
    "        image_paths = sorted(glob(os.path.join(root, object_name, scene, 'images', '*')))\n",
    "        \n",
    "        PILImages = [ PIL.Image.open(image_paths[i]) for i in range(n) ]\n",
    "\n",
    "        images = load_images_from_PIL(PILImages, size=512)\n",
    "\n",
    "        pairs = make_pairs(images, scene_graph='complete', prefilter='cyc20', symmetrize=True)\n",
    "        output = inference(pairs, model, device, batch_size=16)\n",
    "\n",
    "        scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)\n",
    "        loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)\n",
    "\n",
    "\n",
    "        poses = scene.get_im_poses().cpu().detach()\n",
    "        poseAnnotations = getPoseAnnotations(os.path.join(root, object_name, 'frame_annotations.js'), scene, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee33a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inference with model on 870 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [00:00<?, ?it/s]/home/soliverosb/dust3r/dust3r/inference.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=bool(use_amp)):\n",
      "/home/soliverosb/dust3r/dust3r/model.py:205: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/soliverosb/dust3r/dust3r/inference.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "100%|██████████| 55/55 [01:30<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (12*,23*) score=np.float64(16.18464469909668)\n",
      " init edge (23,24*) score=np.float64(14.476905822753906)\n",
      " init edge (23,10*) score=np.float64(13.846390724182129)\n",
      " init edge (14*,24) score=np.float64(13.77676773071289)\n",
      " init edge (23,25*) score=np.float64(13.392385482788086)\n",
      " init edge (21*,24) score=np.float64(13.24314022064209)\n",
      " init edge (13*,24) score=np.float64(13.002606391906738)\n",
      " init edge (28*,25) score=np.float64(12.237759590148926)\n",
      " init edge (22*,12) score=np.float64(11.685663223266602)\n",
      " init edge (22,8*) score=np.float64(10.564742088317871)\n",
      " init edge (28,26*) score=np.float64(10.49522876739502)\n",
      " init edge (7*,24) score=np.float64(9.887109756469727)\n",
      " init edge (20*,23) score=np.float64(9.643139839172363)\n",
      " init edge (13,11*) score=np.float64(9.519482612609863)\n",
      " init edge (1*,12) score=np.float64(8.512975692749023)\n",
      " init edge (2*,23) score=np.float64(8.185733795166016)\n",
      " init edge (12,16*) score=np.float64(6.656954288482666)\n",
      " init edge (13,9*) score=np.float64(6.651501655578613)\n",
      " init edge (7,3*) score=np.float64(5.544500350952148)\n",
      " init edge (23,4*) score=np.float64(5.057535648345947)\n",
      " init edge (22,29*) score=np.float64(4.511457443237305)\n",
      " init edge (19*,20) score=np.float64(4.027135372161865)\n",
      " init edge (24,15*) score=np.float64(3.607835292816162)\n",
      " init edge (0*,28) score=np.float64(2.539544105529785)\n",
      " init edge (17*,25) score=np.float64(14.143184661865234)\n",
      " init edge (6*,17) score=np.float64(13.255047798156738)\n",
      " init edge (11,27*) score=np.float64(12.154653549194336)\n",
      " init edge (5*,27) score=np.float64(6.627800464630127)\n",
      " init edge (18*,27) score=np.float64(5.944089889526367)\n",
      " init loss = 0.00738320779055357\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps', 'im_poses', 'im_focals']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:26<00:00,  2.05it/s, lr=1.27413e-06 loss=0.00431767]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95ebe1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReferenceFrameTransform(X, Y):\n",
    "    mu_x = torch.mean(X, dim=0)\n",
    "    mu_y = torch.mean(Y, dim=0)\n",
    "\n",
    "    var_x = torch.square(X - mu_x).sum(dim=1).mean()\n",
    "    var_y = torch.square(Y - mu_y).sum(dim=1).mean()\n",
    "    \n",
    "    cov_XY = torch.mm((Y - mu_y).T,(X - mu_x))/len(X)\n",
    "\n",
    "    U, D, Vh = torch.linalg.svd(cov_XY)\n",
    "\n",
    "    S = torch.eye(X.shape[1])\n",
    "\n",
    "    if X.shape[1]-1 < torch.linalg.matrix_rank(cov_XY):\n",
    "        if torch.linalg.det(cov_XY) < 0:\n",
    "            S[-1, -1] = -1\n",
    "    else: \n",
    "        if torch.linalg.det(U) * torch.linalg.det(Vh) < 0:\n",
    "            S[-1, -1] = -1\n",
    "    \n",
    "    c = 1/var_x*torch.trace(torch.diag(D)@S)\n",
    "    R = U @ S @ Vh\n",
    "    t = mu_y - c*R@mu_x\n",
    "\n",
    "    return R, t, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e3f1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllCombinations(batch):\n",
    "    indices_i = []\n",
    "    indices_j = []\n",
    "    batch_size = len(batch)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(i + 1, batch_size):\n",
    "            indices_i.append(i)\n",
    "            indices_j.append(j)\n",
    "\n",
    "    indices_i = torch.tensor(indices_i)\n",
    "    indices_j = torch.tensor(indices_j)\n",
    "\n",
    "    tensors_i = batch[indices_i]\n",
    "    tensors_j = batch[indices_j]\n",
    "\n",
    "    return tensors_i, tensors_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b6ec9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcRTA(positionPreds, positionGt, tau=15):\n",
    "\n",
    "    positionsPreds_i, positionsPreds_j = getAllCombinations(positionPreds)\n",
    "    positionsGt_i, positionsGt_j = getAllCombinations(positionGt)\n",
    "\n",
    "    positionDifferencesPreds = positionsPreds_j - positionsPreds_i\n",
    "    positionDifferencesGt = positionsGt_j - positionsGt_i\n",
    "\n",
    "    positionDifferencesPreds = torch.nn.functional.normalize(positionDifferencesPreds)\n",
    "    positionDifferencesGt = torch.nn.functional.normalize(positionDifferencesGt)\n",
    "\n",
    "    positionDotDifferences = torch.sum(positionDifferencesPreds*positionDifferencesGt, dim=1)\n",
    "    positionDotAngles = torch.rad2deg(torch.acos(positionDotDifferences))\n",
    "\n",
    "    RTA = torch.where(positionDotAngles < tau, 1.0, 0.0).mean()\n",
    "\n",
    "    return RTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96dcb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcRRA(rotationPreds, rotationGt, tau=15):\n",
    "    rotationPreds_i, rotationPreds_j = getAllCombinations(rotationPreds)\n",
    "    rotationGt_i, rotationGt_j = getAllCombinations(rotationGt)\n",
    "\n",
    "    rotationPreds_ij = torch.matmul(rotationPreds_i, rotationPreds_j.transpose(1,2))\n",
    "    rotationGt_ij = torch.matmul(rotationGt_i, rotationGt_j.transpose(1,2))\n",
    "    \n",
    "    rotationGtPred_ij = torch.matmul(rotationGt_ij.transpose(1,2), rotationPreds_ij)\n",
    "\n",
    "    traces = torch.einsum('bii->b', rotationGtPred_ij)\n",
    "\n",
    "    rotationAngles_ij = torch.rad2deg(torch.acos((traces -1)/2))\n",
    "\n",
    "    RRA = torch.where(rotationAngles_ij < tau, 1.0, 0.0).mean()\n",
    "\n",
    "    return RRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2aae21b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9862), tensor(0.9977))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcError(HPreds, HGt):\n",
    "    positionPreds = HPreds[:, :3, 3]\n",
    "    positionGt = HGt[:, :3, 3]\n",
    "\n",
    "    rotationPreds = HPreds[:, :3, :3]\n",
    "    rotationGt = HGt[:, :3, :3]\n",
    "\n",
    "    \n",
    "    R, t, c = getReferenceFrameTransform(positionPreds, positionGt)\n",
    "\n",
    "    positionPredsAligned = c*torch.matmul(positionPreds, R.T) + t\n",
    "    rotationPredsAligned = torch.matmul(R, rotationPreds)\n",
    "\n",
    "    RTA = calcRTA(positionPredsAligned, positionGt)\n",
    "\n",
    "    RRA = calcRRA(rotationPredsAligned, rotationGt)\n",
    "    \n",
    "    return RTA, RRA\n",
    "    \n",
    "\n",
    "calcError(poses, transformationMatrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b460c734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9862), tensor(0.9931))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcError(poses, transformationMatrices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dStuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
